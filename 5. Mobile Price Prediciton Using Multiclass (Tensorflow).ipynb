{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "k6FfdI48f-HT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "D_DX0O_Tg9jO",
        "outputId": "a9894973-7250-43d2-fbc8-7f827d6a8d71"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
              "0            842     0          2.2         0   1       0           7    0.6   \n",
              "1           1021     1          0.5         1   0       1          53    0.7   \n",
              "2            563     1          0.5         1   2       1          41    0.9   \n",
              "3            615     1          2.5         0   0       0          10    0.8   \n",
              "4           1821     1          1.2         0  13       1          44    0.6   \n",
              "\n",
              "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
              "0        188        2  ...         20       756  2549     9     7         19   \n",
              "1        136        3  ...        905      1988  2631    17     3          7   \n",
              "2        145        5  ...       1263      1716  2603    11     2          9   \n",
              "3        131        6  ...       1216      1786  2769    16     8         11   \n",
              "4        141        2  ...       1208      1212  1411     8     2         15   \n",
              "\n",
              "   three_g  touch_screen  wifi  price_range  \n",
              "0        0             0     1            1  \n",
              "1        1             1     0            2  \n",
              "2        1             1     0            2  \n",
              "3        1             0     0            2  \n",
              "4        1             1     0            1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-117e0803-47e3-4329-bbd4-d733af12cd7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>...</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842</td>\n",
              "      <td>0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>188</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>756</td>\n",
              "      <td>2549</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0.7</td>\n",
              "      <td>136</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>905</td>\n",
              "      <td>1988</td>\n",
              "      <td>2631</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>563</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0.9</td>\n",
              "      <td>145</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>1263</td>\n",
              "      <td>1716</td>\n",
              "      <td>2603</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>615</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>131</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>1216</td>\n",
              "      <td>1786</td>\n",
              "      <td>2769</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1821</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>0.6</td>\n",
              "      <td>141</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1208</td>\n",
              "      <td>1212</td>\n",
              "      <td>1411</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-117e0803-47e3-4329-bbd4-d733af12cd7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-117e0803-47e3-4329-bbd4-d733af12cd7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-117e0803-47e3-4329-bbd4-d733af12cd7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DpEXA2OhD9A",
        "outputId": "3de2e4c3-7021-4443-e268-bbc71c39c60b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   battery_power  2000 non-null   int64  \n",
            " 1   blue           2000 non-null   int64  \n",
            " 2   clock_speed    2000 non-null   float64\n",
            " 3   dual_sim       2000 non-null   int64  \n",
            " 4   fc             2000 non-null   int64  \n",
            " 5   four_g         2000 non-null   int64  \n",
            " 6   int_memory     2000 non-null   int64  \n",
            " 7   m_dep          2000 non-null   float64\n",
            " 8   mobile_wt      2000 non-null   int64  \n",
            " 9   n_cores        2000 non-null   int64  \n",
            " 10  pc             2000 non-null   int64  \n",
            " 11  px_height      2000 non-null   int64  \n",
            " 12  px_width       2000 non-null   int64  \n",
            " 13  ram            2000 non-null   int64  \n",
            " 14  sc_h           2000 non-null   int64  \n",
            " 15  sc_w           2000 non-null   int64  \n",
            " 16  talk_time      2000 non-null   int64  \n",
            " 17  three_g        2000 non-null   int64  \n",
            " 18  touch_screen   2000 non-null   int64  \n",
            " 19  wifi           2000 non-null   int64  \n",
            " 20  price_range    2000 non-null   int64  \n",
            "dtypes: float64(2), int64(19)\n",
            "memory usage: 328.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb2Vemx8hGP0",
        "outputId": "0dd94e0b-26d9-4ebd-fcb5-46393eff00e4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "battery_power    0\n",
              "blue             0\n",
              "clock_speed      0\n",
              "dual_sim         0\n",
              "fc               0\n",
              "four_g           0\n",
              "int_memory       0\n",
              "m_dep            0\n",
              "mobile_wt        0\n",
              "n_cores          0\n",
              "pc               0\n",
              "px_height        0\n",
              "px_width         0\n",
              "ram              0\n",
              "sc_h             0\n",
              "sc_w             0\n",
              "talk_time        0\n",
              "three_g          0\n",
              "touch_screen     0\n",
              "wifi             0\n",
              "price_range      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW7w47xXhK6U",
        "outputId": "3bffc63a-c364-4ea2-d62a-e9f503a4c9f8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['price_range'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02qjrG2wiwBc",
        "outputId": "59e96c60-76af-4deb-b5f3-bb13c0affb3f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    500\n",
              "2    500\n",
              "3    500\n",
              "0    500\n",
              "Name: price_range, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop('price_range',axis=1)\n",
        "y = df['price_range']"
      ],
      "metadata": {
        "id": "jPDRkpmPiptk"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(x,y,random_state=1,test_size=0.3)"
      ],
      "metadata": {
        "id": "JM-TpS7yjEBD"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "xtrain = ss.fit_transform(xtrain)\n",
        "xtest = ss.transform(xtest)"
      ],
      "metadata": {
        "id": "VXNnRSgIjWpE"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyPgXooNjmLL",
        "outputId": "b14d7e7f-b42f-42f5-f31b-ca9736b6055c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=24,activation='relu',kernel_regularizer=regularizers.l2(0.01),input_shape=(20,)),Dropout(0.50),\n",
        "    tf.keras.layers.Dense(units=4,activation='softmax',kernel_regularizer=regularizers.l2(0.01))\n",
        "])"
      ],
      "metadata": {
        "id": "t8Kt1s-_jo7T"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_zlxqYjj__V",
        "outputId": "93a824c2-db98-4d47-c66e-515e80a5bab6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 24)                504       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 604\n",
            "Trainable params: 604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3U5Z1aUdkCGc"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "cb = EarlyStopping(\n",
        "    monitor = 'val_loss',\n",
        "    min_delta = 0.00001,\n",
        "    patience = 20,\n",
        "    verbose = 1,\n",
        "    mode = 'auto',\n",
        "    baseline = None,\n",
        "    restore_best_weights = False\n",
        ")"
      ],
      "metadata": {
        "id": "QJH40DndkWr8"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = model.fit(xtrain,ytrain,epochs=5000,callbacks=cb,validation_data=(xtest,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJATPldbkeWU",
        "outputId": "49dc5c8b-c759-498d-b645-fc191992c2f5"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5000\n",
            "44/44 [==============================] - 1s 8ms/step - loss: 1.9005 - accuracy: 0.2829 - val_loss: 1.6329 - val_accuracy: 0.3250\n",
            "Epoch 2/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7432 - accuracy: 0.3093 - val_loss: 1.5555 - val_accuracy: 0.3617\n",
            "Epoch 3/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6656 - accuracy: 0.3114 - val_loss: 1.4966 - val_accuracy: 0.4083\n",
            "Epoch 4/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.5831 - accuracy: 0.3657 - val_loss: 1.4503 - val_accuracy: 0.4367\n",
            "Epoch 5/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.5040 - accuracy: 0.4207 - val_loss: 1.4097 - val_accuracy: 0.4750\n",
            "Epoch 6/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.4751 - accuracy: 0.3993 - val_loss: 1.3729 - val_accuracy: 0.4983\n",
            "Epoch 7/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.4348 - accuracy: 0.4379 - val_loss: 1.3392 - val_accuracy: 0.5233\n",
            "Epoch 8/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.3925 - accuracy: 0.4521 - val_loss: 1.3094 - val_accuracy: 0.5433\n",
            "Epoch 9/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.3829 - accuracy: 0.4600 - val_loss: 1.2806 - val_accuracy: 0.5750\n",
            "Epoch 10/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.3410 - accuracy: 0.4700 - val_loss: 1.2552 - val_accuracy: 0.5867\n",
            "Epoch 11/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.3107 - accuracy: 0.4886 - val_loss: 1.2306 - val_accuracy: 0.5917\n",
            "Epoch 12/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.2974 - accuracy: 0.4993 - val_loss: 1.2079 - val_accuracy: 0.6033\n",
            "Epoch 13/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.2505 - accuracy: 0.5279 - val_loss: 1.1854 - val_accuracy: 0.6117\n",
            "Epoch 14/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.2277 - accuracy: 0.5257 - val_loss: 1.1648 - val_accuracy: 0.6300\n",
            "Epoch 15/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.1896 - accuracy: 0.5714 - val_loss: 1.1442 - val_accuracy: 0.6233\n",
            "Epoch 16/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.1765 - accuracy: 0.5621 - val_loss: 1.1251 - val_accuracy: 0.6367\n",
            "Epoch 17/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.1753 - accuracy: 0.5579 - val_loss: 1.1072 - val_accuracy: 0.6500\n",
            "Epoch 18/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.1444 - accuracy: 0.5771 - val_loss: 1.0897 - val_accuracy: 0.6517\n",
            "Epoch 19/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.1457 - accuracy: 0.5636 - val_loss: 1.0742 - val_accuracy: 0.6650\n",
            "Epoch 20/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.1051 - accuracy: 0.6029 - val_loss: 1.0585 - val_accuracy: 0.6833\n",
            "Epoch 21/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.1004 - accuracy: 0.5971 - val_loss: 1.0436 - val_accuracy: 0.6883\n",
            "Epoch 22/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.0947 - accuracy: 0.6029 - val_loss: 1.0296 - val_accuracy: 0.6967\n",
            "Epoch 23/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.0680 - accuracy: 0.6157 - val_loss: 1.0169 - val_accuracy: 0.7100\n",
            "Epoch 24/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.0649 - accuracy: 0.6057 - val_loss: 1.0039 - val_accuracy: 0.7133\n",
            "Epoch 25/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.0460 - accuracy: 0.6307 - val_loss: 0.9924 - val_accuracy: 0.7233\n",
            "Epoch 26/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.0219 - accuracy: 0.6429 - val_loss: 0.9816 - val_accuracy: 0.7300\n",
            "Epoch 27/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.0265 - accuracy: 0.6386 - val_loss: 0.9705 - val_accuracy: 0.7350\n",
            "Epoch 28/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.0033 - accuracy: 0.6564 - val_loss: 0.9596 - val_accuracy: 0.7367\n",
            "Epoch 29/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.0043 - accuracy: 0.6571 - val_loss: 0.9498 - val_accuracy: 0.7500\n",
            "Epoch 30/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9913 - accuracy: 0.6557 - val_loss: 0.9409 - val_accuracy: 0.7533\n",
            "Epoch 31/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9948 - accuracy: 0.6543 - val_loss: 0.9327 - val_accuracy: 0.7533\n",
            "Epoch 32/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.9836 - accuracy: 0.6600 - val_loss: 0.9240 - val_accuracy: 0.7600\n",
            "Epoch 33/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9523 - accuracy: 0.7100 - val_loss: 0.9159 - val_accuracy: 0.7633\n",
            "Epoch 34/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9578 - accuracy: 0.6700 - val_loss: 0.9085 - val_accuracy: 0.7583\n",
            "Epoch 35/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9581 - accuracy: 0.6936 - val_loss: 0.9010 - val_accuracy: 0.7700\n",
            "Epoch 36/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9597 - accuracy: 0.6757 - val_loss: 0.8943 - val_accuracy: 0.7783\n",
            "Epoch 37/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9476 - accuracy: 0.6879 - val_loss: 0.8876 - val_accuracy: 0.7783\n",
            "Epoch 38/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9282 - accuracy: 0.7200 - val_loss: 0.8812 - val_accuracy: 0.7833\n",
            "Epoch 39/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9276 - accuracy: 0.7186 - val_loss: 0.8756 - val_accuracy: 0.7900\n",
            "Epoch 40/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9200 - accuracy: 0.7114 - val_loss: 0.8696 - val_accuracy: 0.7950\n",
            "Epoch 41/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9201 - accuracy: 0.7057 - val_loss: 0.8643 - val_accuracy: 0.8117\n",
            "Epoch 42/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.9090 - accuracy: 0.7250 - val_loss: 0.8584 - val_accuracy: 0.8050\n",
            "Epoch 43/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8996 - accuracy: 0.7214 - val_loss: 0.8529 - val_accuracy: 0.8133\n",
            "Epoch 44/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8917 - accuracy: 0.7350 - val_loss: 0.8479 - val_accuracy: 0.8167\n",
            "Epoch 45/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8922 - accuracy: 0.7271 - val_loss: 0.8427 - val_accuracy: 0.8233\n",
            "Epoch 46/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.8862 - accuracy: 0.7314 - val_loss: 0.8377 - val_accuracy: 0.8233\n",
            "Epoch 47/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8895 - accuracy: 0.7171 - val_loss: 0.8333 - val_accuracy: 0.8317\n",
            "Epoch 48/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8801 - accuracy: 0.7379 - val_loss: 0.8285 - val_accuracy: 0.8317\n",
            "Epoch 49/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8739 - accuracy: 0.7371 - val_loss: 0.8236 - val_accuracy: 0.8300\n",
            "Epoch 50/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8811 - accuracy: 0.7236 - val_loss: 0.8193 - val_accuracy: 0.8317\n",
            "Epoch 51/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8729 - accuracy: 0.7321 - val_loss: 0.8155 - val_accuracy: 0.8383\n",
            "Epoch 52/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.8736 - accuracy: 0.7393 - val_loss: 0.8113 - val_accuracy: 0.8433\n",
            "Epoch 53/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8646 - accuracy: 0.7629 - val_loss: 0.8073 - val_accuracy: 0.8400\n",
            "Epoch 54/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8757 - accuracy: 0.7386 - val_loss: 0.8038 - val_accuracy: 0.8400\n",
            "Epoch 55/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.8514 - accuracy: 0.7436 - val_loss: 0.8001 - val_accuracy: 0.8417\n",
            "Epoch 56/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.8479 - accuracy: 0.7650 - val_loss: 0.7968 - val_accuracy: 0.8417\n",
            "Epoch 57/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8589 - accuracy: 0.7400 - val_loss: 0.7939 - val_accuracy: 0.8467\n",
            "Epoch 58/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8502 - accuracy: 0.7436 - val_loss: 0.7904 - val_accuracy: 0.8483\n",
            "Epoch 59/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.8490 - accuracy: 0.7407 - val_loss: 0.7874 - val_accuracy: 0.8533\n",
            "Epoch 60/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8320 - accuracy: 0.7571 - val_loss: 0.7838 - val_accuracy: 0.8533\n",
            "Epoch 61/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8242 - accuracy: 0.7643 - val_loss: 0.7805 - val_accuracy: 0.8550\n",
            "Epoch 62/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8200 - accuracy: 0.7729 - val_loss: 0.7769 - val_accuracy: 0.8550\n",
            "Epoch 63/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8271 - accuracy: 0.7564 - val_loss: 0.7740 - val_accuracy: 0.8617\n",
            "Epoch 64/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8274 - accuracy: 0.7700 - val_loss: 0.7713 - val_accuracy: 0.8600\n",
            "Epoch 65/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.8225 - accuracy: 0.7729 - val_loss: 0.7684 - val_accuracy: 0.8600\n",
            "Epoch 66/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.8327 - accuracy: 0.7529 - val_loss: 0.7658 - val_accuracy: 0.8600\n",
            "Epoch 67/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.8164 - accuracy: 0.7786 - val_loss: 0.7628 - val_accuracy: 0.8583\n",
            "Epoch 68/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8030 - accuracy: 0.7936 - val_loss: 0.7600 - val_accuracy: 0.8567\n",
            "Epoch 69/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8286 - accuracy: 0.7650 - val_loss: 0.7576 - val_accuracy: 0.8583\n",
            "Epoch 70/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.8137 - accuracy: 0.7693 - val_loss: 0.7555 - val_accuracy: 0.8583\n",
            "Epoch 71/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8048 - accuracy: 0.7757 - val_loss: 0.7528 - val_accuracy: 0.8583\n",
            "Epoch 72/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8063 - accuracy: 0.7743 - val_loss: 0.7509 - val_accuracy: 0.8617\n",
            "Epoch 73/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7934 - accuracy: 0.7957 - val_loss: 0.7483 - val_accuracy: 0.8633\n",
            "Epoch 74/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8117 - accuracy: 0.7721 - val_loss: 0.7458 - val_accuracy: 0.8583\n",
            "Epoch 75/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.8046 - accuracy: 0.7671 - val_loss: 0.7433 - val_accuracy: 0.8617\n",
            "Epoch 76/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7912 - accuracy: 0.7871 - val_loss: 0.7410 - val_accuracy: 0.8600\n",
            "Epoch 77/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7893 - accuracy: 0.7771 - val_loss: 0.7388 - val_accuracy: 0.8650\n",
            "Epoch 78/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7929 - accuracy: 0.7836 - val_loss: 0.7363 - val_accuracy: 0.8617\n",
            "Epoch 79/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7737 - accuracy: 0.8043 - val_loss: 0.7337 - val_accuracy: 0.8650\n",
            "Epoch 80/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7854 - accuracy: 0.7850 - val_loss: 0.7317 - val_accuracy: 0.8633\n",
            "Epoch 81/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7791 - accuracy: 0.7879 - val_loss: 0.7292 - val_accuracy: 0.8667\n",
            "Epoch 82/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7765 - accuracy: 0.8029 - val_loss: 0.7274 - val_accuracy: 0.8633\n",
            "Epoch 83/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7869 - accuracy: 0.7829 - val_loss: 0.7252 - val_accuracy: 0.8700\n",
            "Epoch 84/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7735 - accuracy: 0.7807 - val_loss: 0.7235 - val_accuracy: 0.8717\n",
            "Epoch 85/5000\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.7855 - accuracy: 0.7757 - val_loss: 0.7214 - val_accuracy: 0.8650\n",
            "Epoch 86/5000\n",
            "44/44 [==============================] - 1s 14ms/step - loss: 0.7747 - accuracy: 0.7836 - val_loss: 0.7194 - val_accuracy: 0.8683\n",
            "Epoch 87/5000\n",
            "44/44 [==============================] - 1s 14ms/step - loss: 0.7846 - accuracy: 0.7921 - val_loss: 0.7178 - val_accuracy: 0.8650\n",
            "Epoch 88/5000\n",
            "44/44 [==============================] - 1s 12ms/step - loss: 0.7819 - accuracy: 0.7850 - val_loss: 0.7160 - val_accuracy: 0.8700\n",
            "Epoch 89/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7781 - accuracy: 0.7843 - val_loss: 0.7143 - val_accuracy: 0.8700\n",
            "Epoch 90/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7655 - accuracy: 0.8029 - val_loss: 0.7126 - val_accuracy: 0.8683\n",
            "Epoch 91/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7631 - accuracy: 0.8114 - val_loss: 0.7107 - val_accuracy: 0.8667\n",
            "Epoch 92/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7650 - accuracy: 0.7914 - val_loss: 0.7088 - val_accuracy: 0.8750\n",
            "Epoch 93/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7581 - accuracy: 0.8050 - val_loss: 0.7070 - val_accuracy: 0.8717\n",
            "Epoch 94/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7561 - accuracy: 0.8071 - val_loss: 0.7052 - val_accuracy: 0.8750\n",
            "Epoch 95/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7731 - accuracy: 0.7907 - val_loss: 0.7034 - val_accuracy: 0.8783\n",
            "Epoch 96/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.7971 - val_loss: 0.7018 - val_accuracy: 0.8750\n",
            "Epoch 97/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7608 - accuracy: 0.7936 - val_loss: 0.6998 - val_accuracy: 0.8833\n",
            "Epoch 98/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7433 - accuracy: 0.8079 - val_loss: 0.6974 - val_accuracy: 0.8900\n",
            "Epoch 99/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.8014 - val_loss: 0.6959 - val_accuracy: 0.8900\n",
            "Epoch 100/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.8029 - val_loss: 0.6943 - val_accuracy: 0.8967\n",
            "Epoch 101/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.8121 - val_loss: 0.6924 - val_accuracy: 0.8933\n",
            "Epoch 102/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.8214 - val_loss: 0.6903 - val_accuracy: 0.8900\n",
            "Epoch 103/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.7477 - accuracy: 0.7979 - val_loss: 0.6888 - val_accuracy: 0.8883\n",
            "Epoch 104/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7541 - accuracy: 0.7864 - val_loss: 0.6872 - val_accuracy: 0.8933\n",
            "Epoch 105/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7472 - accuracy: 0.8036 - val_loss: 0.6854 - val_accuracy: 0.8900\n",
            "Epoch 106/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7483 - accuracy: 0.8021 - val_loss: 0.6838 - val_accuracy: 0.8950\n",
            "Epoch 107/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7357 - accuracy: 0.8129 - val_loss: 0.6821 - val_accuracy: 0.8967\n",
            "Epoch 108/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.7317 - accuracy: 0.8186 - val_loss: 0.6805 - val_accuracy: 0.9000\n",
            "Epoch 109/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7306 - accuracy: 0.8121 - val_loss: 0.6786 - val_accuracy: 0.9067\n",
            "Epoch 110/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7395 - accuracy: 0.7993 - val_loss: 0.6773 - val_accuracy: 0.9050\n",
            "Epoch 111/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7410 - accuracy: 0.8021 - val_loss: 0.6762 - val_accuracy: 0.8933\n",
            "Epoch 112/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7364 - accuracy: 0.8064 - val_loss: 0.6747 - val_accuracy: 0.9050\n",
            "Epoch 113/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7411 - accuracy: 0.8064 - val_loss: 0.6736 - val_accuracy: 0.9017\n",
            "Epoch 114/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7297 - accuracy: 0.8236 - val_loss: 0.6722 - val_accuracy: 0.9017\n",
            "Epoch 115/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7382 - accuracy: 0.7993 - val_loss: 0.6704 - val_accuracy: 0.9033\n",
            "Epoch 116/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.8179 - val_loss: 0.6686 - val_accuracy: 0.9050\n",
            "Epoch 117/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7342 - accuracy: 0.8036 - val_loss: 0.6672 - val_accuracy: 0.9083\n",
            "Epoch 118/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7297 - accuracy: 0.8071 - val_loss: 0.6659 - val_accuracy: 0.9050\n",
            "Epoch 119/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7228 - accuracy: 0.8043 - val_loss: 0.6645 - val_accuracy: 0.9067\n",
            "Epoch 120/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7226 - accuracy: 0.8271 - val_loss: 0.6636 - val_accuracy: 0.9067\n",
            "Epoch 121/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7299 - accuracy: 0.7986 - val_loss: 0.6619 - val_accuracy: 0.9133\n",
            "Epoch 122/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7281 - accuracy: 0.8107 - val_loss: 0.6610 - val_accuracy: 0.9050\n",
            "Epoch 123/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7258 - accuracy: 0.8157 - val_loss: 0.6605 - val_accuracy: 0.9067\n",
            "Epoch 124/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.8100 - val_loss: 0.6591 - val_accuracy: 0.9100\n",
            "Epoch 125/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.7180 - accuracy: 0.8193 - val_loss: 0.6581 - val_accuracy: 0.9117\n",
            "Epoch 126/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7264 - accuracy: 0.8043 - val_loss: 0.6565 - val_accuracy: 0.9133\n",
            "Epoch 127/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7149 - accuracy: 0.8329 - val_loss: 0.6550 - val_accuracy: 0.9133\n",
            "Epoch 128/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.8271 - val_loss: 0.6540 - val_accuracy: 0.9133\n",
            "Epoch 129/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.8321 - val_loss: 0.6530 - val_accuracy: 0.9117\n",
            "Epoch 130/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.8393 - val_loss: 0.6519 - val_accuracy: 0.9083\n",
            "Epoch 131/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.8179 - val_loss: 0.6505 - val_accuracy: 0.9133\n",
            "Epoch 132/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7174 - accuracy: 0.8136 - val_loss: 0.6493 - val_accuracy: 0.9117\n",
            "Epoch 133/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.8329 - val_loss: 0.6477 - val_accuracy: 0.9200\n",
            "Epoch 134/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7168 - accuracy: 0.8279 - val_loss: 0.6469 - val_accuracy: 0.9183\n",
            "Epoch 135/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.8250 - val_loss: 0.6457 - val_accuracy: 0.9183\n",
            "Epoch 136/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7374 - accuracy: 0.8064 - val_loss: 0.6447 - val_accuracy: 0.9283\n",
            "Epoch 137/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7123 - accuracy: 0.8314 - val_loss: 0.6437 - val_accuracy: 0.9150\n",
            "Epoch 138/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7029 - accuracy: 0.8321 - val_loss: 0.6424 - val_accuracy: 0.9133\n",
            "Epoch 139/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7103 - accuracy: 0.8171 - val_loss: 0.6411 - val_accuracy: 0.9217\n",
            "Epoch 140/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7079 - accuracy: 0.8293 - val_loss: 0.6405 - val_accuracy: 0.9167\n",
            "Epoch 141/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.8271 - val_loss: 0.6392 - val_accuracy: 0.9233\n",
            "Epoch 142/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7107 - accuracy: 0.8171 - val_loss: 0.6377 - val_accuracy: 0.9250\n",
            "Epoch 143/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7138 - accuracy: 0.8250 - val_loss: 0.6363 - val_accuracy: 0.9250\n",
            "Epoch 144/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.8279 - val_loss: 0.6347 - val_accuracy: 0.9300\n",
            "Epoch 145/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.8300 - val_loss: 0.6337 - val_accuracy: 0.9283\n",
            "Epoch 146/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.8329 - val_loss: 0.6327 - val_accuracy: 0.9283\n",
            "Epoch 147/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6974 - accuracy: 0.8293 - val_loss: 0.6316 - val_accuracy: 0.9233\n",
            "Epoch 148/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.8264 - val_loss: 0.6305 - val_accuracy: 0.9267\n",
            "Epoch 149/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.8179 - val_loss: 0.6296 - val_accuracy: 0.9283\n",
            "Epoch 150/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.8286 - val_loss: 0.6281 - val_accuracy: 0.9267\n",
            "Epoch 151/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.8279 - val_loss: 0.6270 - val_accuracy: 0.9300\n",
            "Epoch 152/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.8443 - val_loss: 0.6266 - val_accuracy: 0.9267\n",
            "Epoch 153/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.8286 - val_loss: 0.6256 - val_accuracy: 0.9283\n",
            "Epoch 154/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.8236 - val_loss: 0.6247 - val_accuracy: 0.9350\n",
            "Epoch 155/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.8221 - val_loss: 0.6243 - val_accuracy: 0.9350\n",
            "Epoch 156/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6915 - accuracy: 0.8400 - val_loss: 0.6238 - val_accuracy: 0.9283\n",
            "Epoch 157/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.8400 - val_loss: 0.6230 - val_accuracy: 0.9283\n",
            "Epoch 158/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6988 - accuracy: 0.8129 - val_loss: 0.6222 - val_accuracy: 0.9317\n",
            "Epoch 159/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.8386 - val_loss: 0.6206 - val_accuracy: 0.9267\n",
            "Epoch 160/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.8250 - val_loss: 0.6197 - val_accuracy: 0.9267\n",
            "Epoch 161/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.8400 - val_loss: 0.6191 - val_accuracy: 0.9267\n",
            "Epoch 162/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.8329 - val_loss: 0.6187 - val_accuracy: 0.9267\n",
            "Epoch 163/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.8457 - val_loss: 0.6182 - val_accuracy: 0.9267\n",
            "Epoch 164/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.8271 - val_loss: 0.6173 - val_accuracy: 0.9317\n",
            "Epoch 165/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.8421 - val_loss: 0.6162 - val_accuracy: 0.9300\n",
            "Epoch 166/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.8421 - val_loss: 0.6154 - val_accuracy: 0.9350\n",
            "Epoch 167/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.8314 - val_loss: 0.6144 - val_accuracy: 0.9233\n",
            "Epoch 168/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.8407 - val_loss: 0.6141 - val_accuracy: 0.9300\n",
            "Epoch 169/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.8450 - val_loss: 0.6128 - val_accuracy: 0.9267\n",
            "Epoch 170/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.8471 - val_loss: 0.6121 - val_accuracy: 0.9300\n",
            "Epoch 171/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.8479 - val_loss: 0.6118 - val_accuracy: 0.9283\n",
            "Epoch 172/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6750 - accuracy: 0.8514 - val_loss: 0.6109 - val_accuracy: 0.9317\n",
            "Epoch 173/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.8321 - val_loss: 0.6101 - val_accuracy: 0.9300\n",
            "Epoch 174/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.8564 - val_loss: 0.6092 - val_accuracy: 0.9333\n",
            "Epoch 175/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6653 - accuracy: 0.8536 - val_loss: 0.6084 - val_accuracy: 0.9300\n",
            "Epoch 176/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.8364 - val_loss: 0.6075 - val_accuracy: 0.9333\n",
            "Epoch 177/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6689 - accuracy: 0.8450 - val_loss: 0.6067 - val_accuracy: 0.9333\n",
            "Epoch 178/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.8279 - val_loss: 0.6065 - val_accuracy: 0.9333\n",
            "Epoch 179/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.8414 - val_loss: 0.6062 - val_accuracy: 0.9333\n",
            "Epoch 180/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.8371 - val_loss: 0.6051 - val_accuracy: 0.9400\n",
            "Epoch 181/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6846 - accuracy: 0.8293 - val_loss: 0.6042 - val_accuracy: 0.9417\n",
            "Epoch 182/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.8357 - val_loss: 0.6037 - val_accuracy: 0.9400\n",
            "Epoch 183/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6896 - accuracy: 0.8429 - val_loss: 0.6033 - val_accuracy: 0.9400\n",
            "Epoch 184/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6759 - accuracy: 0.8436 - val_loss: 0.6027 - val_accuracy: 0.9417\n",
            "Epoch 185/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.8357 - val_loss: 0.6023 - val_accuracy: 0.9383\n",
            "Epoch 186/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.8536 - val_loss: 0.6016 - val_accuracy: 0.9350\n",
            "Epoch 187/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.8429 - val_loss: 0.6006 - val_accuracy: 0.9400\n",
            "Epoch 188/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.8493 - val_loss: 0.5999 - val_accuracy: 0.9417\n",
            "Epoch 189/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.8429 - val_loss: 0.5995 - val_accuracy: 0.9383\n",
            "Epoch 190/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.8329 - val_loss: 0.5990 - val_accuracy: 0.9367\n",
            "Epoch 191/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.8521 - val_loss: 0.5984 - val_accuracy: 0.9433\n",
            "Epoch 192/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.8471 - val_loss: 0.5973 - val_accuracy: 0.9417\n",
            "Epoch 193/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.8614 - val_loss: 0.5969 - val_accuracy: 0.9467\n",
            "Epoch 194/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.8486 - val_loss: 0.5964 - val_accuracy: 0.9417\n",
            "Epoch 195/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.8493 - val_loss: 0.5959 - val_accuracy: 0.9450\n",
            "Epoch 196/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.8357 - val_loss: 0.5955 - val_accuracy: 0.9450\n",
            "Epoch 197/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.8543 - val_loss: 0.5952 - val_accuracy: 0.9433\n",
            "Epoch 198/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.8400 - val_loss: 0.5946 - val_accuracy: 0.9467\n",
            "Epoch 199/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.8621 - val_loss: 0.5946 - val_accuracy: 0.9450\n",
            "Epoch 200/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.8443 - val_loss: 0.5941 - val_accuracy: 0.9467\n",
            "Epoch 201/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.8486 - val_loss: 0.5935 - val_accuracy: 0.9450\n",
            "Epoch 202/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.8386 - val_loss: 0.5930 - val_accuracy: 0.9433\n",
            "Epoch 203/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.8500 - val_loss: 0.5924 - val_accuracy: 0.9433\n",
            "Epoch 204/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.8507 - val_loss: 0.5919 - val_accuracy: 0.9433\n",
            "Epoch 205/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.8671 - val_loss: 0.5918 - val_accuracy: 0.9417\n",
            "Epoch 206/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.8364 - val_loss: 0.5908 - val_accuracy: 0.9450\n",
            "Epoch 207/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.8400 - val_loss: 0.5904 - val_accuracy: 0.9450\n",
            "Epoch 208/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.8457 - val_loss: 0.5903 - val_accuracy: 0.9433\n",
            "Epoch 209/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.8650 - val_loss: 0.5905 - val_accuracy: 0.9417\n",
            "Epoch 210/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.8371 - val_loss: 0.5899 - val_accuracy: 0.9467\n",
            "Epoch 211/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.8443 - val_loss: 0.5895 - val_accuracy: 0.9433\n",
            "Epoch 212/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.8500 - val_loss: 0.5885 - val_accuracy: 0.9483\n",
            "Epoch 213/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.8550 - val_loss: 0.5878 - val_accuracy: 0.9450\n",
            "Epoch 214/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.8529 - val_loss: 0.5873 - val_accuracy: 0.9433\n",
            "Epoch 215/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.8571 - val_loss: 0.5868 - val_accuracy: 0.9450\n",
            "Epoch 216/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.8436 - val_loss: 0.5869 - val_accuracy: 0.9483\n",
            "Epoch 217/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.8443 - val_loss: 0.5874 - val_accuracy: 0.9467\n",
            "Epoch 218/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.8686 - val_loss: 0.5873 - val_accuracy: 0.9400\n",
            "Epoch 219/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.8493 - val_loss: 0.5874 - val_accuracy: 0.9367\n",
            "Epoch 220/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.8457 - val_loss: 0.5873 - val_accuracy: 0.9450\n",
            "Epoch 221/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.8643 - val_loss: 0.5869 - val_accuracy: 0.9417\n",
            "Epoch 222/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.8543 - val_loss: 0.5861 - val_accuracy: 0.9450\n",
            "Epoch 223/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.8607 - val_loss: 0.5854 - val_accuracy: 0.9450\n",
            "Epoch 224/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.8514 - val_loss: 0.5852 - val_accuracy: 0.9417\n",
            "Epoch 225/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.8471 - val_loss: 0.5852 - val_accuracy: 0.9483\n",
            "Epoch 226/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.8450 - val_loss: 0.5850 - val_accuracy: 0.9500\n",
            "Epoch 227/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.8643 - val_loss: 0.5841 - val_accuracy: 0.9533\n",
            "Epoch 228/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6638 - accuracy: 0.8479 - val_loss: 0.5838 - val_accuracy: 0.9500\n",
            "Epoch 229/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.8407 - val_loss: 0.5830 - val_accuracy: 0.9517\n",
            "Epoch 230/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.8521 - val_loss: 0.5825 - val_accuracy: 0.9483\n",
            "Epoch 231/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.8564 - val_loss: 0.5819 - val_accuracy: 0.9533\n",
            "Epoch 232/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.8586 - val_loss: 0.5817 - val_accuracy: 0.9517\n",
            "Epoch 233/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.8614 - val_loss: 0.5813 - val_accuracy: 0.9483\n",
            "Epoch 234/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.8586 - val_loss: 0.5817 - val_accuracy: 0.9500\n",
            "Epoch 235/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.8557 - val_loss: 0.5814 - val_accuracy: 0.9500\n",
            "Epoch 236/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.8543 - val_loss: 0.5815 - val_accuracy: 0.9483\n",
            "Epoch 237/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.8500 - val_loss: 0.5809 - val_accuracy: 0.9533\n",
            "Epoch 238/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.8600 - val_loss: 0.5811 - val_accuracy: 0.9500\n",
            "Epoch 239/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.8621 - val_loss: 0.5800 - val_accuracy: 0.9483\n",
            "Epoch 240/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.8571 - val_loss: 0.5802 - val_accuracy: 0.9500\n",
            "Epoch 241/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.8571 - val_loss: 0.5798 - val_accuracy: 0.9483\n",
            "Epoch 242/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6623 - accuracy: 0.8493 - val_loss: 0.5795 - val_accuracy: 0.9467\n",
            "Epoch 243/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6567 - accuracy: 0.8586 - val_loss: 0.5791 - val_accuracy: 0.9517\n",
            "Epoch 244/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6540 - accuracy: 0.8529 - val_loss: 0.5795 - val_accuracy: 0.9450\n",
            "Epoch 245/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6605 - accuracy: 0.8471 - val_loss: 0.5788 - val_accuracy: 0.9467\n",
            "Epoch 246/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6464 - accuracy: 0.8650 - val_loss: 0.5788 - val_accuracy: 0.9450\n",
            "Epoch 247/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6409 - accuracy: 0.8671 - val_loss: 0.5784 - val_accuracy: 0.9500\n",
            "Epoch 248/5000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.6582 - accuracy: 0.8507 - val_loss: 0.5782 - val_accuracy: 0.9467\n",
            "Epoch 249/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6565 - accuracy: 0.8614 - val_loss: 0.5781 - val_accuracy: 0.9483\n",
            "Epoch 250/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.8657 - val_loss: 0.5784 - val_accuracy: 0.9483\n",
            "Epoch 251/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6641 - accuracy: 0.8529 - val_loss: 0.5780 - val_accuracy: 0.9467\n",
            "Epoch 252/5000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.6490 - accuracy: 0.8571 - val_loss: 0.5780 - val_accuracy: 0.9517\n",
            "Epoch 253/5000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.6649 - accuracy: 0.8607 - val_loss: 0.5780 - val_accuracy: 0.9517\n",
            "Epoch 254/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.8564 - val_loss: 0.5782 - val_accuracy: 0.9500\n",
            "Epoch 255/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.8507 - val_loss: 0.5785 - val_accuracy: 0.9483\n",
            "Epoch 256/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.8586 - val_loss: 0.5778 - val_accuracy: 0.9500\n",
            "Epoch 257/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.8629 - val_loss: 0.5771 - val_accuracy: 0.9500\n",
            "Epoch 258/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.8700 - val_loss: 0.5768 - val_accuracy: 0.9517\n",
            "Epoch 259/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.8586 - val_loss: 0.5766 - val_accuracy: 0.9500\n",
            "Epoch 260/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.8643 - val_loss: 0.5760 - val_accuracy: 0.9500\n",
            "Epoch 261/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.8543 - val_loss: 0.5755 - val_accuracy: 0.9483\n",
            "Epoch 262/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.8693 - val_loss: 0.5756 - val_accuracy: 0.9500\n",
            "Epoch 263/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.8614 - val_loss: 0.5753 - val_accuracy: 0.9500\n",
            "Epoch 264/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.8664 - val_loss: 0.5752 - val_accuracy: 0.9467\n",
            "Epoch 265/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.8514 - val_loss: 0.5744 - val_accuracy: 0.9517\n",
            "Epoch 266/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.8529 - val_loss: 0.5747 - val_accuracy: 0.9517\n",
            "Epoch 267/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.8743 - val_loss: 0.5740 - val_accuracy: 0.9517\n",
            "Epoch 268/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.8507 - val_loss: 0.5738 - val_accuracy: 0.9550\n",
            "Epoch 269/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.8514 - val_loss: 0.5735 - val_accuracy: 0.9517\n",
            "Epoch 270/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.8764 - val_loss: 0.5735 - val_accuracy: 0.9483\n",
            "Epoch 271/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.8629 - val_loss: 0.5735 - val_accuracy: 0.9483\n",
            "Epoch 272/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.8571 - val_loss: 0.5739 - val_accuracy: 0.9483\n",
            "Epoch 273/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.8700 - val_loss: 0.5740 - val_accuracy: 0.9517\n",
            "Epoch 274/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.8700 - val_loss: 0.5728 - val_accuracy: 0.9500\n",
            "Epoch 275/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.8686 - val_loss: 0.5722 - val_accuracy: 0.9517\n",
            "Epoch 276/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.8536 - val_loss: 0.5716 - val_accuracy: 0.9517\n",
            "Epoch 277/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.8564 - val_loss: 0.5710 - val_accuracy: 0.9517\n",
            "Epoch 278/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.8571 - val_loss: 0.5710 - val_accuracy: 0.9533\n",
            "Epoch 279/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.8471 - val_loss: 0.5708 - val_accuracy: 0.9533\n",
            "Epoch 280/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.8443 - val_loss: 0.5709 - val_accuracy: 0.9550\n",
            "Epoch 281/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.8686 - val_loss: 0.5711 - val_accuracy: 0.9517\n",
            "Epoch 282/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.8571 - val_loss: 0.5715 - val_accuracy: 0.9533\n",
            "Epoch 283/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.8786 - val_loss: 0.5713 - val_accuracy: 0.9517\n",
            "Epoch 284/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.8736 - val_loss: 0.5716 - val_accuracy: 0.9517\n",
            "Epoch 285/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.8529 - val_loss: 0.5716 - val_accuracy: 0.9500\n",
            "Epoch 286/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.8629 - val_loss: 0.5715 - val_accuracy: 0.9517\n",
            "Epoch 287/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.8679 - val_loss: 0.5717 - val_accuracy: 0.9500\n",
            "Epoch 288/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.8457 - val_loss: 0.5715 - val_accuracy: 0.9467\n",
            "Epoch 289/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.8671 - val_loss: 0.5711 - val_accuracy: 0.9517\n",
            "Epoch 290/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.8686 - val_loss: 0.5714 - val_accuracy: 0.9483\n",
            "Epoch 291/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.8850 - val_loss: 0.5711 - val_accuracy: 0.9450\n",
            "Epoch 292/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.8657 - val_loss: 0.5709 - val_accuracy: 0.9500\n",
            "Epoch 293/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.8664 - val_loss: 0.5712 - val_accuracy: 0.9483\n",
            "Epoch 294/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.8507 - val_loss: 0.5708 - val_accuracy: 0.9483\n",
            "Epoch 295/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.8779 - val_loss: 0.5702 - val_accuracy: 0.9500\n",
            "Epoch 296/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.8593 - val_loss: 0.5701 - val_accuracy: 0.9500\n",
            "Epoch 297/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.8750 - val_loss: 0.5699 - val_accuracy: 0.9483\n",
            "Epoch 298/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.8593 - val_loss: 0.5696 - val_accuracy: 0.9517\n",
            "Epoch 299/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.8707 - val_loss: 0.5697 - val_accuracy: 0.9483\n",
            "Epoch 300/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.8636 - val_loss: 0.5697 - val_accuracy: 0.9450\n",
            "Epoch 301/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.8771 - val_loss: 0.5696 - val_accuracy: 0.9450\n",
            "Epoch 302/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.8743 - val_loss: 0.5701 - val_accuracy: 0.9467\n",
            "Epoch 303/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.8793 - val_loss: 0.5698 - val_accuracy: 0.9500\n",
            "Epoch 304/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.8521 - val_loss: 0.5699 - val_accuracy: 0.9450\n",
            "Epoch 305/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.8779 - val_loss: 0.5689 - val_accuracy: 0.9483\n",
            "Epoch 306/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.8664 - val_loss: 0.5689 - val_accuracy: 0.9483\n",
            "Epoch 307/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.8657 - val_loss: 0.5687 - val_accuracy: 0.9467\n",
            "Epoch 308/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.8650 - val_loss: 0.5692 - val_accuracy: 0.9467\n",
            "Epoch 309/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6455 - accuracy: 0.8721 - val_loss: 0.5690 - val_accuracy: 0.9450\n",
            "Epoch 310/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6436 - accuracy: 0.8607 - val_loss: 0.5689 - val_accuracy: 0.9483\n",
            "Epoch 311/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.8643 - val_loss: 0.5687 - val_accuracy: 0.9467\n",
            "Epoch 312/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.8614 - val_loss: 0.5680 - val_accuracy: 0.9433\n",
            "Epoch 313/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6280 - accuracy: 0.8764 - val_loss: 0.5675 - val_accuracy: 0.9450\n",
            "Epoch 314/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6331 - accuracy: 0.8764 - val_loss: 0.5675 - val_accuracy: 0.9500\n",
            "Epoch 315/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6349 - accuracy: 0.8736 - val_loss: 0.5671 - val_accuracy: 0.9467\n",
            "Epoch 316/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.8429 - val_loss: 0.5674 - val_accuracy: 0.9450\n",
            "Epoch 317/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.8614 - val_loss: 0.5673 - val_accuracy: 0.9467\n",
            "Epoch 318/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.8643 - val_loss: 0.5671 - val_accuracy: 0.9483\n",
            "Epoch 319/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.8750 - val_loss: 0.5675 - val_accuracy: 0.9467\n",
            "Epoch 320/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6400 - accuracy: 0.8714 - val_loss: 0.5670 - val_accuracy: 0.9467\n",
            "Epoch 321/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6457 - accuracy: 0.8593 - val_loss: 0.5670 - val_accuracy: 0.9450\n",
            "Epoch 322/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.8614 - val_loss: 0.5668 - val_accuracy: 0.9500\n",
            "Epoch 323/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.8657 - val_loss: 0.5671 - val_accuracy: 0.9517\n",
            "Epoch 324/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.8707 - val_loss: 0.5673 - val_accuracy: 0.9517\n",
            "Epoch 325/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.8707 - val_loss: 0.5673 - val_accuracy: 0.9500\n",
            "Epoch 326/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.8629 - val_loss: 0.5673 - val_accuracy: 0.9517\n",
            "Epoch 327/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.8643 - val_loss: 0.5673 - val_accuracy: 0.9517\n",
            "Epoch 328/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6277 - accuracy: 0.8800 - val_loss: 0.5670 - val_accuracy: 0.9533\n",
            "Epoch 329/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.8814 - val_loss: 0.5671 - val_accuracy: 0.9517\n",
            "Epoch 330/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.8757 - val_loss: 0.5669 - val_accuracy: 0.9500\n",
            "Epoch 331/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6273 - accuracy: 0.8779 - val_loss: 0.5668 - val_accuracy: 0.9533\n",
            "Epoch 332/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.8714 - val_loss: 0.5670 - val_accuracy: 0.9467\n",
            "Epoch 333/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.8743 - val_loss: 0.5670 - val_accuracy: 0.9483\n",
            "Epoch 334/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.8793 - val_loss: 0.5670 - val_accuracy: 0.9500\n",
            "Epoch 335/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.8643 - val_loss: 0.5672 - val_accuracy: 0.9500\n",
            "Epoch 336/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.8771 - val_loss: 0.5666 - val_accuracy: 0.9450\n",
            "Epoch 337/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.8600 - val_loss: 0.5669 - val_accuracy: 0.9500\n",
            "Epoch 338/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.8507 - val_loss: 0.5669 - val_accuracy: 0.9500\n",
            "Epoch 339/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.8571 - val_loss: 0.5669 - val_accuracy: 0.9467\n",
            "Epoch 340/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.8700 - val_loss: 0.5668 - val_accuracy: 0.9500\n",
            "Epoch 341/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.8614 - val_loss: 0.5671 - val_accuracy: 0.9500\n",
            "Epoch 342/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.8679 - val_loss: 0.5665 - val_accuracy: 0.9500\n",
            "Epoch 343/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.8700 - val_loss: 0.5664 - val_accuracy: 0.9517\n",
            "Epoch 344/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.8579 - val_loss: 0.5664 - val_accuracy: 0.9517\n",
            "Epoch 345/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.8786 - val_loss: 0.5660 - val_accuracy: 0.9500\n",
            "Epoch 346/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.8571 - val_loss: 0.5659 - val_accuracy: 0.9517\n",
            "Epoch 347/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.8700 - val_loss: 0.5661 - val_accuracy: 0.9517\n",
            "Epoch 348/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.8714 - val_loss: 0.5656 - val_accuracy: 0.9550\n",
            "Epoch 349/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.8657 - val_loss: 0.5657 - val_accuracy: 0.9517\n",
            "Epoch 350/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.8779 - val_loss: 0.5660 - val_accuracy: 0.9533\n",
            "Epoch 351/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.8771 - val_loss: 0.5656 - val_accuracy: 0.9483\n",
            "Epoch 352/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.8643 - val_loss: 0.5657 - val_accuracy: 0.9483\n",
            "Epoch 353/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.8829 - val_loss: 0.5651 - val_accuracy: 0.9517\n",
            "Epoch 354/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.8779 - val_loss: 0.5649 - val_accuracy: 0.9500\n",
            "Epoch 355/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.8857 - val_loss: 0.5650 - val_accuracy: 0.9517\n",
            "Epoch 356/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.8657 - val_loss: 0.5649 - val_accuracy: 0.9467\n",
            "Epoch 357/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.8800 - val_loss: 0.5646 - val_accuracy: 0.9500\n",
            "Epoch 358/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.8843 - val_loss: 0.5650 - val_accuracy: 0.9450\n",
            "Epoch 359/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.8750 - val_loss: 0.5643 - val_accuracy: 0.9483\n",
            "Epoch 360/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.8786 - val_loss: 0.5642 - val_accuracy: 0.9500\n",
            "Epoch 361/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.8550 - val_loss: 0.5644 - val_accuracy: 0.9500\n",
            "Epoch 362/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.8843 - val_loss: 0.5651 - val_accuracy: 0.9467\n",
            "Epoch 363/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.8664 - val_loss: 0.5649 - val_accuracy: 0.9467\n",
            "Epoch 364/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.8693 - val_loss: 0.5650 - val_accuracy: 0.9483\n",
            "Epoch 365/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.8757 - val_loss: 0.5648 - val_accuracy: 0.9483\n",
            "Epoch 366/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.8757 - val_loss: 0.5649 - val_accuracy: 0.9467\n",
            "Epoch 367/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.8836 - val_loss: 0.5646 - val_accuracy: 0.9483\n",
            "Epoch 368/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.8500 - val_loss: 0.5652 - val_accuracy: 0.9500\n",
            "Epoch 369/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.8857 - val_loss: 0.5644 - val_accuracy: 0.9500\n",
            "Epoch 370/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.8871 - val_loss: 0.5637 - val_accuracy: 0.9483\n",
            "Epoch 371/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.8850 - val_loss: 0.5642 - val_accuracy: 0.9517\n",
            "Epoch 372/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.8671 - val_loss: 0.5640 - val_accuracy: 0.9517\n",
            "Epoch 373/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.8629 - val_loss: 0.5643 - val_accuracy: 0.9533\n",
            "Epoch 374/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.8779 - val_loss: 0.5645 - val_accuracy: 0.9483\n",
            "Epoch 375/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6358 - accuracy: 0.8764 - val_loss: 0.5652 - val_accuracy: 0.9517\n",
            "Epoch 376/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.8743 - val_loss: 0.5647 - val_accuracy: 0.9500\n",
            "Epoch 377/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.8600 - val_loss: 0.5645 - val_accuracy: 0.9500\n",
            "Epoch 378/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6219 - accuracy: 0.8771 - val_loss: 0.5636 - val_accuracy: 0.9517\n",
            "Epoch 379/5000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.6418 - accuracy: 0.8650 - val_loss: 0.5641 - val_accuracy: 0.9483\n",
            "Epoch 380/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6193 - accuracy: 0.8886 - val_loss: 0.5644 - val_accuracy: 0.9500\n",
            "Epoch 381/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6333 - accuracy: 0.8786 - val_loss: 0.5640 - val_accuracy: 0.9500\n",
            "Epoch 382/5000\n",
            "44/44 [==============================] - 1s 27ms/step - loss: 0.6482 - accuracy: 0.8686 - val_loss: 0.5640 - val_accuracy: 0.9500\n",
            "Epoch 383/5000\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.6317 - accuracy: 0.8664 - val_loss: 0.5649 - val_accuracy: 0.9450\n",
            "Epoch 384/5000\n",
            "44/44 [==============================] - 1s 14ms/step - loss: 0.6406 - accuracy: 0.8586 - val_loss: 0.5646 - val_accuracy: 0.9500\n",
            "Epoch 385/5000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 0.6259 - accuracy: 0.8800 - val_loss: 0.5643 - val_accuracy: 0.9500\n",
            "Epoch 386/5000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.6109 - accuracy: 0.8879 - val_loss: 0.5636 - val_accuracy: 0.9517\n",
            "Epoch 387/5000\n",
            "44/44 [==============================] - 1s 11ms/step - loss: 0.6319 - accuracy: 0.8771 - val_loss: 0.5632 - val_accuracy: 0.9517\n",
            "Epoch 388/5000\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.6394 - accuracy: 0.8600 - val_loss: 0.5637 - val_accuracy: 0.9500\n",
            "Epoch 389/5000\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.6391 - accuracy: 0.8679 - val_loss: 0.5636 - val_accuracy: 0.9517\n",
            "Epoch 390/5000\n",
            "44/44 [==============================] - 1s 12ms/step - loss: 0.6178 - accuracy: 0.8886 - val_loss: 0.5630 - val_accuracy: 0.9517\n",
            "Epoch 391/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6226 - accuracy: 0.8757 - val_loss: 0.5624 - val_accuracy: 0.9483\n",
            "Epoch 392/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6227 - accuracy: 0.8736 - val_loss: 0.5630 - val_accuracy: 0.9517\n",
            "Epoch 393/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.8793 - val_loss: 0.5635 - val_accuracy: 0.9483\n",
            "Epoch 394/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6421 - accuracy: 0.8643 - val_loss: 0.5634 - val_accuracy: 0.9500\n",
            "Epoch 395/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6269 - accuracy: 0.8743 - val_loss: 0.5633 - val_accuracy: 0.9533\n",
            "Epoch 396/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.8864 - val_loss: 0.5634 - val_accuracy: 0.9500\n",
            "Epoch 397/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.8729 - val_loss: 0.5633 - val_accuracy: 0.9483\n",
            "Epoch 398/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.8936 - val_loss: 0.5634 - val_accuracy: 0.9517\n",
            "Epoch 399/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.8807 - val_loss: 0.5631 - val_accuracy: 0.9517\n",
            "Epoch 400/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.8850 - val_loss: 0.5632 - val_accuracy: 0.9517\n",
            "Epoch 401/5000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.6257 - accuracy: 0.8800 - val_loss: 0.5625 - val_accuracy: 0.9483\n",
            "Epoch 402/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6255 - accuracy: 0.8829 - val_loss: 0.5623 - val_accuracy: 0.9517\n",
            "Epoch 403/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.8786 - val_loss: 0.5623 - val_accuracy: 0.9500\n",
            "Epoch 404/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.8907 - val_loss: 0.5622 - val_accuracy: 0.9517\n",
            "Epoch 405/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.8764 - val_loss: 0.5624 - val_accuracy: 0.9500\n",
            "Epoch 406/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.8921 - val_loss: 0.5624 - val_accuracy: 0.9500\n",
            "Epoch 407/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.8700 - val_loss: 0.5626 - val_accuracy: 0.9500\n",
            "Epoch 408/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.8721 - val_loss: 0.5625 - val_accuracy: 0.9533\n",
            "Epoch 409/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.8679 - val_loss: 0.5628 - val_accuracy: 0.9533\n",
            "Epoch 410/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.8607 - val_loss: 0.5638 - val_accuracy: 0.9500\n",
            "Epoch 411/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.8921 - val_loss: 0.5634 - val_accuracy: 0.9483\n",
            "Epoch 412/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.8793 - val_loss: 0.5633 - val_accuracy: 0.9483\n",
            "Epoch 413/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.8586 - val_loss: 0.5634 - val_accuracy: 0.9483\n",
            "Epoch 414/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.8943 - val_loss: 0.5630 - val_accuracy: 0.9483\n",
            "Epoch 415/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6354 - accuracy: 0.8664 - val_loss: 0.5628 - val_accuracy: 0.9500\n",
            "Epoch 416/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.8764 - val_loss: 0.5625 - val_accuracy: 0.9500\n",
            "Epoch 417/5000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.6242 - accuracy: 0.8743 - val_loss: 0.5624 - val_accuracy: 0.9467\n",
            "Epoch 418/5000\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.6194 - accuracy: 0.8807 - val_loss: 0.5620 - val_accuracy: 0.9483\n",
            "Epoch 419/5000\n",
            "44/44 [==============================] - 1s 11ms/step - loss: 0.6189 - accuracy: 0.8914 - val_loss: 0.5621 - val_accuracy: 0.9500\n",
            "Epoch 420/5000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.6306 - accuracy: 0.8750 - val_loss: 0.5625 - val_accuracy: 0.9500\n",
            "Epoch 421/5000\n",
            "44/44 [==============================] - 1s 30ms/step - loss: 0.6175 - accuracy: 0.8821 - val_loss: 0.5626 - val_accuracy: 0.9467\n",
            "Epoch 422/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6228 - accuracy: 0.8893 - val_loss: 0.5615 - val_accuracy: 0.9500\n",
            "Epoch 423/5000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.6345 - accuracy: 0.8636 - val_loss: 0.5612 - val_accuracy: 0.9500\n",
            "Epoch 424/5000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 0.6294 - accuracy: 0.8757 - val_loss: 0.5613 - val_accuracy: 0.9517\n",
            "Epoch 425/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.8686 - val_loss: 0.5611 - val_accuracy: 0.9500\n",
            "Epoch 426/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.8807 - val_loss: 0.5605 - val_accuracy: 0.9483\n",
            "Epoch 427/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.8671 - val_loss: 0.5608 - val_accuracy: 0.9517\n",
            "Epoch 428/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.8664 - val_loss: 0.5616 - val_accuracy: 0.9517\n",
            "Epoch 429/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.8886 - val_loss: 0.5614 - val_accuracy: 0.9483\n",
            "Epoch 430/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6241 - accuracy: 0.8786 - val_loss: 0.5615 - val_accuracy: 0.9483\n",
            "Epoch 431/5000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.8821 - val_loss: 0.5616 - val_accuracy: 0.9483\n",
            "Epoch 432/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.8857 - val_loss: 0.5611 - val_accuracy: 0.9517\n",
            "Epoch 433/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.8764 - val_loss: 0.5612 - val_accuracy: 0.9500\n",
            "Epoch 434/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.8729 - val_loss: 0.5617 - val_accuracy: 0.9467\n",
            "Epoch 435/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.8850 - val_loss: 0.5601 - val_accuracy: 0.9500\n",
            "Epoch 436/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.8736 - val_loss: 0.5599 - val_accuracy: 0.9483\n",
            "Epoch 437/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.8621 - val_loss: 0.5603 - val_accuracy: 0.9517\n",
            "Epoch 438/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.8786 - val_loss: 0.5601 - val_accuracy: 0.9517\n",
            "Epoch 439/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.8779 - val_loss: 0.5602 - val_accuracy: 0.9517\n",
            "Epoch 440/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.8843 - val_loss: 0.5601 - val_accuracy: 0.9517\n",
            "Epoch 441/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.8757 - val_loss: 0.5611 - val_accuracy: 0.9517\n",
            "Epoch 442/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.8750 - val_loss: 0.5610 - val_accuracy: 0.9483\n",
            "Epoch 443/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.8836 - val_loss: 0.5608 - val_accuracy: 0.9483\n",
            "Epoch 444/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.8764 - val_loss: 0.5610 - val_accuracy: 0.9500\n",
            "Epoch 445/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.8771 - val_loss: 0.5604 - val_accuracy: 0.9500\n",
            "Epoch 446/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.8729 - val_loss: 0.5604 - val_accuracy: 0.9483\n",
            "Epoch 447/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.8807 - val_loss: 0.5606 - val_accuracy: 0.9500\n",
            "Epoch 448/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.8850 - val_loss: 0.5605 - val_accuracy: 0.9483\n",
            "Epoch 449/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.8729 - val_loss: 0.5602 - val_accuracy: 0.9500\n",
            "Epoch 450/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.8857 - val_loss: 0.5601 - val_accuracy: 0.9500\n",
            "Epoch 451/5000\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.8843 - val_loss: 0.5603 - val_accuracy: 0.9483\n",
            "Epoch 452/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.8750 - val_loss: 0.5599 - val_accuracy: 0.9483\n",
            "Epoch 453/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.8857 - val_loss: 0.5600 - val_accuracy: 0.9483\n",
            "Epoch 454/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.8714 - val_loss: 0.5602 - val_accuracy: 0.9483\n",
            "Epoch 455/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.8829 - val_loss: 0.5601 - val_accuracy: 0.9483\n",
            "Epoch 456/5000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.8671 - val_loss: 0.5601 - val_accuracy: 0.9517\n",
            "Epoch 456: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training_loss :',model.evaluate(xtrain,ytrain))\n",
        "print('Testing_loss :',model.evaluate(xtest,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAm7d2_Ykrhr",
        "outputId": "6a27a166-0835-47c1-a834-ec4caf034b72"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.9714\n",
            "Training_loss : [0.5305634140968323, 0.9714285731315613]\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.9517\n",
            "Testing_loss : [0.5600715279579163, 0.9516666531562805]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(xtest).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLBWj0vJlYth",
        "outputId": "d6cdcfdb-c973-484b-9dc0-3378c8642566"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yddeFwUDnFLk",
        "outputId": "b907973a-9679-4b94-fda4-0676efd2a61e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.87, 0.13, 0.  , 0.  ],\n",
              "       [0.51, 0.48, 0.02, 0.  ],\n",
              "       [0.29, 0.66, 0.05, 0.  ],\n",
              "       ...,\n",
              "       [0.01, 0.39, 0.56, 0.04],\n",
              "       [0.  , 0.  , 0.05, 0.95],\n",
              "       [0.  , 0.  , 0.14, 0.86]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfZTRIZxnJW1",
        "outputId": "312eadeb-9f06-43da-b8d9-3bce8664c142"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.4858777 , -1.00142959,  1.33481858, ...,  0.57515083,\n",
              "        -1.01294087, -0.99714693],\n",
              "       [-0.55939856,  0.99857245,  0.35275407, ...,  0.57515083,\n",
              "         0.98722446, -0.99714693],\n",
              "       [-1.46232663,  0.99857245, -1.24310077, ...,  0.57515083,\n",
              "         0.98722446,  1.00286124],\n",
              "       ...,\n",
              "       [-1.09931738, -1.00142959, -0.87482658, ...,  0.57515083,\n",
              "         0.98722446,  1.00286124],\n",
              "       [ 0.48367864, -1.00142959,  0.10723794, ...,  0.57515083,\n",
              "         0.98722446, -0.99714693],\n",
              "       [ 0.29757896, -1.00142959,  1.70309277, ...,  0.57515083,\n",
              "        -1.01294087,  1.00286124]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = [np.argmax(i) for i in Y_pred]\n",
        "Y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIiDxlFBnOjl",
        "outputId": "d3026f70-806c-4b01-808d-486418cbf13e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "print(classification_report(ytest,Y_pred))\n",
        "print(confusion_matrix(ytest,Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqfKx9K0nXWd",
        "outputId": "40c862c5-4749-4002-e1a4-e5b054d0033a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       135\n",
            "           1       0.96      0.93      0.94       149\n",
            "           2       0.95      0.90      0.93       168\n",
            "           3       0.94      0.98      0.96       148\n",
            "\n",
            "    accuracy                           0.95       600\n",
            "   macro avg       0.95      0.95      0.95       600\n",
            "weighted avg       0.95      0.95      0.95       600\n",
            "\n",
            "[[135   0   0   0]\n",
            " [  6 138   5   0]\n",
            " [  0   6 152  10]\n",
            " [  0   0   3 145]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hH0b30JfnaJ8"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('test.csv')\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "tgCCGI64oFZF",
        "outputId": "8800d653-b4c6-4631-b0e7-2080f9e8085e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
              "0   1           1043     1          1.8         1  14       0           5   \n",
              "1   2            841     1          0.5         1   4       1          61   \n",
              "2   3           1807     1          2.8         0   1       0          27   \n",
              "3   4           1546     0          0.5         1  18       1          25   \n",
              "4   5           1434     0          1.4         0  11       1          49   \n",
              "\n",
              "   m_dep  mobile_wt  ...  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
              "0    0.1        193  ...  16        226      1412  3476    12     7   \n",
              "1    0.8        191  ...  12        746       857  3895     6     0   \n",
              "2    0.9        186  ...   4       1270      1366  2396    17    10   \n",
              "3    0.5         96  ...  20        295      1752  3893    10     0   \n",
              "4    0.5        108  ...  18        749       810  1773    15     8   \n",
              "\n",
              "   talk_time  three_g  touch_screen  wifi  \n",
              "0          2        0             1     0  \n",
              "1          7        1             0     0  \n",
              "2         10        0             1     1  \n",
              "3          7        1             1     0  \n",
              "4          7        1             0     1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca403847-ece8-47b3-831f-537bea193ef1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>...</th>\n",
              "      <th>pc</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1043</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>193</td>\n",
              "      <td>...</td>\n",
              "      <td>16</td>\n",
              "      <td>226</td>\n",
              "      <td>1412</td>\n",
              "      <td>3476</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>841</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>0.8</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>746</td>\n",
              "      <td>857</td>\n",
              "      <td>3895</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1807</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0.9</td>\n",
              "      <td>186</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>1270</td>\n",
              "      <td>1366</td>\n",
              "      <td>2396</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1546</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>96</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>295</td>\n",
              "      <td>1752</td>\n",
              "      <td>3893</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1434</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>0.5</td>\n",
              "      <td>108</td>\n",
              "      <td>...</td>\n",
              "      <td>18</td>\n",
              "      <td>749</td>\n",
              "      <td>810</td>\n",
              "      <td>1773</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca403847-ece8-47b3-831f-537bea193ef1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca403847-ece8-47b3-831f-537bea193ef1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca403847-ece8-47b3-831f-537bea193ef1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.drop('id',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "h2l4MyOToLIl"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_price = model.predict(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4ha3iKloRBd",
        "outputId": "ac0e77cc-5278-479c-b09a-2c6ab75bb3e9"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrz6P8HJozl9",
        "outputId": "303af9f2-8532-4bf3-f1a7-2070623e0876"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.99999994],\n",
              "       [0.        , 0.        , 0.        , 0.99999994],\n",
              "       [0.        , 0.        , 0.        , 0.99999994],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , 0.99999994],\n",
              "       [0.        , 0.        , 0.        , 0.99999994],\n",
              "       [0.        , 0.        , 0.        , 0.99999994]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_price = [np.argmax(i) for i in predicted_price]\n",
        "predicted_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVTxxg-Doh4N",
        "outputId": "531880bc-1f82-4a6e-bcc9-5511009119ca"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['price_range'] = predicted_price"
      ],
      "metadata": {
        "id": "c-02nS2yoZvd"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_ySpLnoxod98",
        "outputId": "2dfb7421-bcac-4fd8-e232-7dc2afd3f904"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
              "0             1043     1          1.8         1  14       0           5   \n",
              "1              841     1          0.5         1   4       1          61   \n",
              "2             1807     1          2.8         0   1       0          27   \n",
              "3             1546     0          0.5         1  18       1          25   \n",
              "4             1434     0          1.4         0  11       1          49   \n",
              "..             ...   ...          ...       ...  ..     ...         ...   \n",
              "995           1700     1          1.9         0   0       1          54   \n",
              "996            609     0          1.8         1   0       0          13   \n",
              "997           1185     0          1.4         0   1       1           8   \n",
              "998           1533     1          0.5         1   0       0          50   \n",
              "999           1270     1          0.5         0   4       1          35   \n",
              "\n",
              "     m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
              "0      0.1        193        3  ...        226      1412  3476    12     7   \n",
              "1      0.8        191        5  ...        746       857  3895     6     0   \n",
              "2      0.9        186        3  ...       1270      1366  2396    17    10   \n",
              "3      0.5         96        8  ...        295      1752  3893    10     0   \n",
              "4      0.5        108        6  ...        749       810  1773    15     8   \n",
              "..     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
              "995    0.5        170        7  ...        644       913  2121    14     8   \n",
              "996    0.9        186        4  ...       1152      1632  1933     8     1   \n",
              "997    0.5         80        1  ...        477       825  1223     5     0   \n",
              "998    0.4        171        2  ...         38       832  2509    15    11   \n",
              "999    0.1        140        6  ...        457       608  2828     9     2   \n",
              "\n",
              "     talk_time  three_g  touch_screen  wifi  price_range  \n",
              "0            2        0             1     0            3  \n",
              "1            7        1             0     0            3  \n",
              "2           10        0             1     1            3  \n",
              "3            7        1             1     0            3  \n",
              "4            7        1             0     1            3  \n",
              "..         ...      ...           ...   ...          ...  \n",
              "995         15        1             1     0            3  \n",
              "996         19        0             1     1            3  \n",
              "997         14        1             0     0            3  \n",
              "998          6        0             1     0            3  \n",
              "999          3        1             0     1            3  \n",
              "\n",
              "[1000 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b224524-9aca-4237-af84-3e7d31fb3f21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>...</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1043</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>193</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>226</td>\n",
              "      <td>1412</td>\n",
              "      <td>3476</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>841</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>0.8</td>\n",
              "      <td>191</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>746</td>\n",
              "      <td>857</td>\n",
              "      <td>3895</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1807</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0.9</td>\n",
              "      <td>186</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>1270</td>\n",
              "      <td>1366</td>\n",
              "      <td>2396</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1546</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>96</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>295</td>\n",
              "      <td>1752</td>\n",
              "      <td>3893</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1434</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>0.5</td>\n",
              "      <td>108</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>749</td>\n",
              "      <td>810</td>\n",
              "      <td>1773</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1700</td>\n",
              "      <td>1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>0.5</td>\n",
              "      <td>170</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>644</td>\n",
              "      <td>913</td>\n",
              "      <td>2121</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>609</td>\n",
              "      <td>0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.9</td>\n",
              "      <td>186</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>1152</td>\n",
              "      <td>1632</td>\n",
              "      <td>1933</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1185</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>477</td>\n",
              "      <td>825</td>\n",
              "      <td>1223</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1533</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0.4</td>\n",
              "      <td>171</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>832</td>\n",
              "      <td>2509</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1270</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0.1</td>\n",
              "      <td>140</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>457</td>\n",
              "      <td>608</td>\n",
              "      <td>2828</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b224524-9aca-4237-af84-3e7d31fb3f21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b224524-9aca-4237-af84-3e7d31fb3f21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b224524-9aca-4237-af84-3e7d31fb3f21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i2XnvPEUo9YN"
      },
      "execution_count": 99,
      "outputs": []
    }
  ]
}